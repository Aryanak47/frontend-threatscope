/**\n * Backend Enhancement Recommendations\n * \n * Based on the analysis of your current database structure vs frontend requirements,\n * here are recommendations to enhance your backend to provide richer data:\n */\n\n/**\n * 1. ADD AGGREGATION QUERIES FOR MISSING METRICS\n * \n * Since you don't have \"Records Affected\" stored per breach, you can calculate this\n * using Elasticsearch aggregations:\n */\n\n// Example: Add to SearchService.java\npublic Map<String, Object> calculateBreachStatistics(String source) {\n    // Count total records for this source\n    Criteria criteria = new Criteria(\"source\").is(source);\n    Query countQuery = new CriteriaQuery(criteria);\n    \n    long recordCount = elasticsearchOperations.count(\n        countQuery, BreachDataIndex.class, IndexCoordinates.of(\"breaches-*\")\n    );\n    \n    // Get unique domains affected\n    // Get date range\n    // Calculate data type distribution\n    \n    return Map.of(\n        \"recordCount\", recordCount,\n        \"uniqueEmails\", calculateUniqueEmails(source),\n        \"uniqueDomains\", calculateUniqueDomains(source),\n        \"hasPasswordPercentage\", calculatePasswordPercentage(source),\n        \"dateRange\", calculateDateRange(source)\n    );\n}\n\n/**\n * 2. ENHANCE SearchResponse.SearchResult\n * \n * Add calculated fields to your SearchResult DTO:\n */\n\n@Data\npublic static class SearchResult {\n    private String id;\n    private String email;\n    private String domain;\n    private String url;\n    private String source;\n    private LocalDateTime timestamp;\n    private String severity;\n    private boolean hasPassword;\n    \n    // NEW: Add calculated fields\n    private Long sourceRecordCount;  // Total records for this source\n    private List<String> dataTypes;  // Available data fields\n    private Boolean isVerified;      // Add verification logic\n    private String breachDescription; // Source-based description\n    private Map<String, Object> sourceStats; // Source statistics\n    \n    public static SearchResult fromStealerLog(StealerLog log, Map<String, Object> sourceStats) {\n        List<String> dataTypes = calculateDataTypes(log);\n        \n        return SearchResult.builder()\n            .id(log.getId())\n            .email(log.getLogin())\n            .domain(log.getDomain())\n            .url(log.getUrl())\n            .source(log.getSource())\n            .timestamp(log.getCreatedAt())\n            .hasPassword(log.getPassword() != null && !log.getPassword().isEmpty())\n            .severity(calculateSeverity(log.getLogin(), log.getDomain()))\n            // NEW calculated fields\n            .sourceRecordCount((Long) sourceStats.get(\"recordCount\"))\n            .dataTypes(dataTypes)\n            .isVerified(calculateVerificationStatus(log))\n            .breachDescription(generateBreachDescription(log.getSource()))\n            .sourceStats(sourceStats)\n            .build();\n    }\n    \n    private static List<String> calculateDataTypes(StealerLog log) {\n        List<String> types = new ArrayList<>();\n        if (log.getLogin() != null) types.add(\"Email/Login\");\n        if (log.getPassword() != null) types.add(\"Password\");\n        if (log.getUrl() != null) types.add(\"URL\");\n        if (log.getDomain() != null) types.add(\"Domain\");\n        if (log.getMetadata() != null) types.add(\"Metadata\");\n        return types;\n    }\n    \n    private static Boolean calculateVerificationStatus(StealerLog log) {\n        // Add your verification logic here\n        // For example: check if password is valid, domain exists, etc.\n        return log.getPassword() != null && \n               log.getLogin() != null && \n               log.getLogin().contains(\"@\");\n    }\n    \n    private static String generateBreachDescription(String source) {\n        // Map source names to descriptions\n        Map<String, String> descriptions = Map.of(\n            \"stealer_logs_10_07_2025\", \"Information stealer malware campaign from October 2025\",\n            \"stealer_logs_09_15_2025\", \"Credential harvesting operation from September 2025\",\n            \"stealer_logs_08_20_2025\", \"Data theft incident from August 2025\"\n        );\n        return descriptions.getOrDefault(source, \"Breach data from \" + source);\n    }\n}\n\n/**\n * 3. ADD SOURCE METADATA TABLE\n * \n * Create a new collection/table to store source information:\n */\n\n@Document(collection = \"breach_sources\")\npublic class BreachSource {\n    @Id\n    private String sourceId;\n    \n    private String sourceName;\n    private String description;\n    private LocalDateTime discoveryDate;\n    private LocalDateTime breachDate;\n    private String severity;\n    private boolean isVerified;\n    private long estimatedRecordCount;\n    private List<String> dataTypes;\n    private Map<String, Object> metadata;\n    \n    // Calculated fields\n    private long actualRecordCount;\n    private LocalDateTime lastUpdated;\n    private Map<String, Long> domainDistribution;\n    private Map<String, Long> countryDistribution;\n}\n\n/**\n * 4. ELASTICSEARCH AGGREGATION QUERIES\n * \n * Add these methods to get comprehensive statistics:\n */\n\npublic Map<String, Object> getSourceStatistics(String source) {\n    String[] indices = indexNameProvider.getAllIndicesPattern();\n    \n    // Build aggregation query\n    Query query = new CriteriaQuery(new Criteria(\"source\").is(source));\n    \n    // Add aggregations for:\n    // - Total record count\n    // - Unique email count  \n    // - Domain distribution\n    // - Password availability percentage\n    // - Date range\n    \n    SearchHits<BreachDataIndex> results = elasticsearchOperations.search(\n        query, BreachDataIndex.class, IndexCoordinates.of(indices)\n    );\n    \n    return Map.of(\n        \"totalRecords\", results.getTotalHits(),\n        \"uniqueEmails\", calculateUniqueEmails(source),\n        \"domainDistribution\", calculateDomainDistribution(source),\n        \"passwordAvailability\", calculatePasswordStats(source),\n        \"dateRange\", calculateDateRange(source)\n    );\n}\n\n/**\n * 5. VERIFICATION LOGIC\n * \n * Add verification based on data quality:\n */\n\npublic boolean isRecordVerified(StealerLog log) {\n    // Verification criteria:\n    boolean hasValidEmail = log.getLogin() != null && \n                           EMAIL_PATTERN.matcher(log.getLogin()).matches();\n    boolean hasValidUrl = log.getUrl() != null && \n                         (log.getUrl().startsWith(\"http\") || log.getUrl().startsWith(\"https\"));\n    boolean hasPassword = log.getPassword() != null && !log.getPassword().isEmpty();\n    boolean domainMatches = checkDomainConsistency(log.getLogin(), log.getUrl());\n    \n    // Consider verified if it meets quality criteria\n    return hasValidEmail && hasValidUrl && hasPassword && domainMatches;\n}\n\n/**\n * 6. ENHANCED SEARCH RESPONSE\n * \n * Update buildSearchResponse method to include enriched data:\n */\n\nprivate SearchResponse buildSearchResponse(Page<BreachDataIndex> esResults, SearchRequest request, long startTime) {\n    Set<String> mongoIds = esResults.getContent().stream()\n            .map(BreachDataIndex::getId)\n            .collect(Collectors.toSet());\n\n    List<StealerLog> fullDocuments = stealerLogRepository.findByIdIn(mongoIds);\n    \n    // Get source statistics for all sources in results\n    Set<String> sources = fullDocuments.stream()\n            .map(StealerLog::getSource)\n            .collect(Collectors.toSet());\n    \n    Map<String, Map<String, Object>> sourceStatsMap = sources.stream()\n            .collect(Collectors.toMap(\n                source -> source,\n                this::getSourceStatistics\n            ));\n\n    // Convert to enhanced search results\n    List<SearchResponse.SearchResult> results = fullDocuments.stream()\n            .map(log -> convertToEnhancedSearchResult(log, sourceStatsMap.get(log.getSource())))\n            .filter(Optional::isPresent)\n            .map(Optional::get)\n            .collect(Collectors.toList());\n\n    // Build comprehensive metadata\n    SearchResponse.SearchMetadata metadata = SearchResponse.SearchMetadata.builder()\n            .sourceBreakdown(calculateSourceBreakdown(results))\n            .severityBreakdown(calculateSeverityBreakdown(results))\n            .verifiedCount(results.stream().mapToLong(r -> r.getIsVerified() ? 1 : 0).sum())\n            .unverifiedCount(results.stream().mapToLong(r -> !r.getIsVerified() ? 1 : 0).sum())\n            .build();\n\n    return SearchResponse.builder()\n            .results(results)\n            .totalResults(esResults.getTotalElements())\n            .currentPage(esResults.getNumber())\n            .totalPages(esResults.getTotalPages())\n            .pageSize(esResults.getSize())\n            .executionTimeMs(System.currentTimeMillis() - startTime)\n            .query(request.getQuery())\n            .searchType(request.getSearchType())\n            .metadata(metadata)\n            .aggregations(sourceStatsMap)\n            .build();\n}\n\n/**\n * IMPLEMENTATION PRIORITY:\n * \n * 1. HIGH PRIORITY (Immediate):\n *    - Add sourceRecordCount calculation using ES aggregations\n *    - Add dataTypes calculation from available fields\n *    - Update SearchResult DTO with new fields\n * \n * 2. MEDIUM PRIORITY (Next Sprint):\n *    - Add BreachSource metadata table\n *    - Implement verification logic\n *    - Add source descriptions\n * \n * 3. LOW PRIORITY (Future):\n *    - Add advanced aggregations for analytics\n *    - Implement data quality scoring\n *    - Add breach timeline analysis\n */